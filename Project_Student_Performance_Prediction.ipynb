{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Dataset Understanding & EDA**"
      ],
      "metadata": {
        "id": "htOcOVTalsTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hUs1E4OAiPQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('student-mat.csv', sep=';')\n",
        "    print(\"--- Dataset loaded successfully! ---\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'student-mat.csv' not found.\")\n",
        "    print(\"Please download the dataset and place it in the same directory.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "D8O41MnaiPTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Data Overview\n",
        "print(\"\\n--- Initial Data Overview ---\")\n",
        "print(\"First 5 Rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "gyxMTqtpiPWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())\n",
        "# EDA Visualizations\n",
        "print(\"\\n--- Performing Exploratory Data Analysis (EDA) ---\")"
      ],
      "metadata": {
        "id": "dQeD7ngUiPZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of the final grade (G3)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['G3'], kde=True, bins=20)\n",
        "plt.title('Distribution of Final Grades (G3)')\n",
        "plt.xlabel('Final Grade')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AtCypCejiPcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "# Select only numeric columns for correlation matrix\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "plt.figure(figsize=(18, 15))\n",
        "sns.heatmap(df[numeric_cols].corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap of Numeric Features')\n",
        "plt.show()\n",
        "print(\"\\n--- Starting Data Preprocessing ---\")"
      ],
      "metadata": {
        "id": "bTgdMEu9iPf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Data Preprocessing**"
      ],
      "metadata": {
        "id": "ETreY6G7ipPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy to avoid modifying the original dataframe\n",
        "df_processed = df.copy()\n",
        "# Encode Categorical Variables using one-hot encoding\n",
        "# We select object type columns to encode\n",
        "categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "df_processed = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=True)\n",
        "print(\"Shape of dataframe after one-hot encoding:\", df_processed.shape)\n",
        "print(\"First 5 rows of preprocessed data:\")\n",
        "print(df_processed.head())"
      ],
      "metadata": {
        "id": "CTMUH9LaiPjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target variables for regression and classification\n",
        "# For classification, we define 'pass' as G3 >= 10 (a common passing grade)\n",
        "df_processed['pass_fail'] = (df_processed['G3'] >= 10).astype(int)\n",
        "# Separate features (X) and target variables (y)\n",
        "X = df_processed.drop(['G3', 'pass_fail'], axis=1)\n",
        "y_reg = df_processed['G3'] # Target for regression (predicting the grade)\n",
        "y_class = df_processed['pass_fail'] # Target for classification (predicting pass/fail)\n",
        "# Import necessary libraries for modeling and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Scale numerical features\n",
        "# Note: One-hot encoded columns are already 0/1, so we only scale original numeric features\n",
        "# However, scaling the entire feature set is common practice and generally safe.\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Split data into training and testing sets for both tasks\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_scaled, y_reg, test_size=0.2, random_state=42)\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_scaled, y_class, test_size=0.2, random_state=42)\n",
        "print(\"\\n--- Data split and scaled successfully. Ready for model building. ---\")"
      ],
      "metadata": {
        "id": "UNRRDn9siPmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Model Building & Evaluation: REGRESSION**"
      ],
      "metadata": {
        "id": "g0U-dl8tjs8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Task 1: REGRESSION (Predicting Final Grade) ---\")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "# Multiple Linear Regression Model\n",
        "mlr = LinearRegression()\n",
        "mlr.fit(X_train_reg, y_train_reg)"
      ],
      "metadata": {
        "id": "sI6fDQOKiPvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred_reg = mlr.predict(X_test_reg)\n",
        "# Evaluate the model\n",
        "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "print(\"\\nMultiple Linear Regression Results:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (RÂ²) Score: {r2:.2f}\")"
      ],
      "metadata": {
        "id": "0G2umdGniPyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Actual vs. Predicted Grades\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_reg, y_pred_reg, alpha=0.7)\n",
        "plt.plot([0, 20], [0, 20], '--', color='red', lw=2) # Line for perfect prediction\n",
        "plt.title('Actual vs. Predicted Final Grades')\n",
        "plt.xlabel('Actual Grades')\n",
        "plt.ylabel('Predicted Grades')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dsbVP8BuiP1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Task 2: CLASSIFICATION (Predicting Pass/Fail) ---\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "# --- Logistic Regression Model ---\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train_class, y_train_class)\n",
        "y_pred_log_reg = log_reg.predict(X_test_class)\n",
        "# --- Decision Tree Model ---\n",
        "dec_tree = DecisionTreeClassifier(random_state=42)\n",
        "dec_tree.fit(X_train_class, y_train_class)\n",
        "y_pred_dec_tree = dec_tree.predict(X_test_class)\n",
        "# Function to evaluate classification models\n",
        "def evaluate_classifier(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"\\n--- {model_name} Results ---\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Precision: {precision:.2f}\")\n",
        "    print(f\"Recall: {recall:.2f}\")\n",
        "    print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "    # Plotting Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fail', 'Pass'], yticklabels=['Fail', 'Pass'])\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "# Evaluate both models\n",
        "evaluate_classifier(y_test_class, y_pred_log_reg, \"Logistic Regression\")\n",
        "evaluate_classifier(y_test_class, y_pred_dec_tree, \"Decision Tree\")"
      ],
      "metadata": {
        "id": "zWt_M7-ZiP4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0PxWmhUiP7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Insights & Key Factors"
      ],
      "metadata": {
        "id": "lbZNnG3Xkzfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Identifying Key Factors for Student Performance ---\")\n",
        "# For regression, we can check the coefficients of the linear model\n",
        "# But with many one-hot encoded features, Decision Tree feature importance is more intuitive.\n",
        "feature_importances = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': dec_tree.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "print(\"\\nTop 10 Most Important Features (from Decision Tree):\")\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "id": "xUBM759PiP-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "print(\"\\n--- Performing Cross-Validation for Decision Tree ---\")\n",
        "dec_tree_cv = DecisionTreeClassifier(random_state=42)\n",
        "cv_scores = cross_val_score(dec_tree_cv, X_scaled, y_class, cv=5, scoring='accuracy')\n",
        "print(f\"Accuracy scores for each of the 5 folds: {cv_scores}\")\n",
        "print(f\"Average cross-validation accuracy: {cv_scores.mean():.2f}\")"
      ],
      "metadata": {
        "id": "Z0EwIw92ppkZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}